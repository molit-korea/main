[2017-08-29T16:31:33,082][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T16:31:33,104][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T16:31:33,936][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:38:54,960][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T16:38:54,963][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T16:38:55,051][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T16:38:55,053][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T16:38:55,088][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T16:38:55,095][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T16:38:55,099][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T16:38:56,187][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T16:38:56,285][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T16:38:56,342][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T16:39:16,454][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T16:39:16,465][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T16:39:19,415][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:39:19,666][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:39:20,110][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:39:20,336][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:39:43,259][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T16:39:43,263][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T16:39:43,337][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T16:39:43,339][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T16:39:43,376][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T16:39:43,383][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T16:39:43,390][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T16:39:43,807][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T16:39:43,865][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T16:39:43,916][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T16:41:25,231][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T16:41:25,241][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T16:41:25,416][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T16:41:51,899][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T16:41:51,902][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T16:41:52,001][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T16:41:52,003][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T16:41:52,037][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T16:41:52,041][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T16:41:52,046][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T16:41:52,506][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T16:41:52,565][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T16:41:52,618][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T21:16:36,979][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T21:16:36,993][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T21:16:41,982][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T21:16:42,071][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"dist"=>"integer", "risk_long_fast"=>"integer", "runtime"=>"integer", "risk_fast"=>"integer", "risk_accel"=>"integer", "risk_start"=>"integer", "risk_decel"=>"integer", "risk_stop"=>"integer", "risk_left"=>"integer", "risk_right"=>"integer", "risk_ut"=>"integer", "risk_dash"=>"integer", "risk_ch"=>"integer", "risk_fast_100"=>"float", "risk_long_fast_100"=>"float", "risk_accel_100"=>"float", "risk_start_100"=>"float", "risk_decel_100"=>"float", "risk_stop_100"=>"float", "risk_left_100"=>"float", "risk_right_100"=>"float", "risk_ut_100"=>"float", "risk_dash_100"=>"float", "risk_ch_100"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "id"=>"23aaa81f8fa1c4f456e240f2123373f12ef30c0c-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T21:16:42,073][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T21:26:42,383][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \",\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:33:47,146][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \",\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:36:22,658][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \",\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:38:38,424][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \",\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:43:49,629][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \"\t\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:45:08,296][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \"\t\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:46:36,531][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \"\t\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:51:21,411][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 113 (byte 182) after filter{\n\tcsv{\n\t\tseparator => \"\t\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\" "}
[2017-08-29T21:53:04,936][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 145 (byte 214) after filter{\n\tcsv{\n\t\tseparator => \"\t\"\n\t\tcolumns => [\"location_name\", \"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"acc_rate\", \"severity\", \"merge_rate\", \"theme\", latitude"}
[2017-08-29T21:53:52,123][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T21:53:53,149][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T21:53:54,227][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T21:53:54,287][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T21:55:07,930][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T21:55:07,945][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T21:55:12,938][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T21:55:13,035][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T21:55:13,038][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T21:55:13,438][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T21:55:24,951][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T21:55:25,411][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T21:55:25,473][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T21:55:25,538][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T21:57:30,852][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T21:57:30,865][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T21:57:35,856][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T21:57:35,966][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}]}}
[2017-08-29T21:57:35,970][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:06:29,955][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:06:30,354][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:06:30,427][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:06:30,489][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:06:36,990][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:06:37,000][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:06:41,993][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:06:42,079][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:06:42,081][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:09:27,145][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:09:27,700][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:09:27,764][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:09:27,817][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:09:30,850][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:09:30,863][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:09:33,830][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T22:10:29,555][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:10:29,931][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:10:30,017][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:10:30,086][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:10:31,489][WARN ][logstash.filters.csv     ] Error parsing csv {:field=>"message", :source=>"\u0000\"\u0000??\\?1\u0000,\u00002\u0000,\u00003\u0000,\u00004\u0000\u0000??????<?0? \u0000^?\"\u0000,\u00003\u00005\u0000,\u00005\u0000,\u00001\u00008\u0000,\u00001\u00000\u0000,\u00002\u0000,\u0000 \u0000 \u0000 \u0000 \u00005\u0000.\u00003\u00003\u0000,\u0000 \u0000 \u0000 \u0000 \u00006\u0000.\u00003\u00000\u0000,\u0000 \u0000 \u0000 \u0000 \u00005\u0000.\u00009\u00001\u0000,\u0000????\u0011?,\u00003\u00007\u0000.\u00005\u00007\u00004\u0000,\u00001\u00002\u00006\u0000.\u00009\u00009\u00000\u0000\r\u0000", :exception=>#<CSV::MalformedCSVError: Illegal quoting in line 1.>}
[2017-08-29T22:10:33,152][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:10:33,231][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:10:38,203][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:10:38,287][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}]}}
[2017-08-29T22:10:38,292][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:12:40,170][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:12:40,542][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:12:40,619][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:12:40,694][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:13:10,509][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:13:10,524][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:13:15,516][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:13:15,637][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:13:15,641][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:18:25,954][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:18:26,386][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:18:26,446][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:18:26,516][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:18:32,540][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:18:32,551][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:18:37,543][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:18:37,636][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:18:38,530][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:21:58,808][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:21:59,241][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:21:59,314][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:21:59,383][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:22:02,841][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:22:02,855][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:22:07,849][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:22:07,943][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}]}}
[2017-08-29T22:22:07,944][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:25:32,543][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:25:32,945][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:25:33,010][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:25:33,073][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:25:35,861][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:25:35,872][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:25:40,864][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:25:40,953][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:25:40,957][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:27:31,353][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:27:31,729][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:27:31,807][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:27:31,868][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:27:32,889][WARN ][logstash.filters.csv     ] Error parsing csv {:field=>"message", :source=>"\u0000\"\u0000??\\?1\u0000,\u00002\u0000,\u00003\u0000,\u00004\u0000\u0000??????<?0? \u0000^?\"\u0000,\u00003\u00005\u0000,\u00005\u0000,\u00001\u00008\u0000,\u00001\u00000\u0000,\u00002\u0000,\u00005\u0000.\u00003\u00003\u0000,\u00006\u0000.\u00003\u0000,\u00005\u0000.\u00009\u00001\u0000,\u0000????\u0011?,\u00003\u00007\u0000.\u00005\u00007\u00004\u0000,\u00001\u00002\u00006\u0000.\u00009\u00009\u0000\r\u0000", :exception=>#<CSV::MalformedCSVError: Illegal quoting in line 1.>}
[2017-08-29T22:27:34,579][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:27:34,589][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:27:39,584][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:27:39,731][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:27:39,736][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:30:27,818][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:30:28,233][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:30:28,295][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:30:28,366][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:30:31,196][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:30:31,206][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:30:36,198][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:30:36,272][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:30:36,276][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:36:58,401][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:36:58,778][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:36:58,844][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:36:58,900][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:37:05,074][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:37:05,089][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:37:10,077][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:37:10,170][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:37:10,174][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:39:12,930][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:39:13,342][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:39:13,409][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:39:13,465][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:39:24,475][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:39:24,489][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:39:29,478][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:39:29,578][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:39:29,593][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:44:16,109][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, => at line 5, column 2 (byte 38) after input{\n\tbeats{\n\t\tport => 5044\n\t\teno\n\t"}
[2017-08-29T22:45:27,888][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:45:28,236][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:45:28,302][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:45:28,355][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:45:32,262][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:45:32,273][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:45:37,272][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:45:37,355][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}]}}
[2017-08-29T22:45:37,362][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:50:33,775][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:50:34,155][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:50:34,220][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:50:34,281][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:52:19,321][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:52:19,339][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:52:20,646][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T22:52:20,885][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T22:52:21,084][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T22:52:43,075][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:52:43,458][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:52:43,520][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:52:43,581][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:52:46,135][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:52:46,144][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:52:51,136][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:52:51,167][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"1a46875e4d0048f3662127fadeccc7c0a7c95f3a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T22:52:51,171][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T22:54:27,509][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T22:54:27,910][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T22:54:27,972][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T22:54:28,038][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T22:54:33,363][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T22:54:33,372][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T22:54:38,370][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T22:54:38,422][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>46, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "acc_rate"=>"integer", "severity"=>"integer", "merge_rate"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"81994c521169f055667573f7eb189a0794bca32a-3"}]=>[{"thread_id"=>29, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>30, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:132:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}]}}
[2017-08-29T22:54:38,424][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T23:00:06,344][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:00:06,763][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:00:06,829][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:00:06,875][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:00:19,161][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:00:19,177][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:00:22,794][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:00:23,212][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:00:23,429][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:00:23,635][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:00:45,881][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:00:46,269][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:00:46,336][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:00:46,392][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:00:49,649][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:00:49,662][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:00:50,901][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:00:51,450][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:01:45,591][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:01:45,973][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:01:46,042][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:01:46,109][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:02:08,517][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:02:08,528][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:02:09,540][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:22:19,780][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:22:20,129][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:22:20,200][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:22:20,259][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:22:25,805][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:22:25,817][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:22:26,599][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:22:26,847][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:26:23,750][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, {, ,, ] at line 10, column 127 (byte 196) after filter{\n\tcsv{\n\t\tseparator => \",\"\n\t\tcolumns => [\"accident\", \"death\", \"very_hurt\", \"light_hurt\", \"injury\", \"many\", \"severity\", \"total\", \"accident_type\", latitude"}
[2017-08-29T23:26:50,854][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:26:50,857][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:26:50,918][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:26:50,919][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:26:50,950][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:26:50,958][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:26:50,960][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:26:51,434][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:26:51,496][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:26:51,546][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:28:06,905][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:06,907][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:06,973][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:06,974][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,013][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,015][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,020][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,020][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,098][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,102][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,159][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,160][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,203][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,204][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,242][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,243][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,297][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,301][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,312][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,313][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,323][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,326][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,342][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,343][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,362][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,363][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,376][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,377][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,388][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,395][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:07,404][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:28:07,407][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:28:08,910][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:08,910][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:08,980][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:08,981][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,017][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,017][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,030][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,030][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,105][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,105][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,163][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,163][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,208][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,209][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,247][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,247][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,304][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,304][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,314][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,314][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,330][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,331][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,348][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,349][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,368][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,369][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,384][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,385][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,401][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,401][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:09,414][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2017-08-29T23:28:09,415][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2017-08-29T23:28:10,963][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:28:10,967][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:29:12,917][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:12,918][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:12,985][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:12,986][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,022][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,022][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,040][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,040][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,113][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,114][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,169][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,170][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,221][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,222][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,256][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,256][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,319][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,320][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,321][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,321][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,338][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,339][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,357][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,357][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,377][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,377][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,390][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,391][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,417][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,417][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:13,424][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:29:13,424][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>8}
[2017-08-29T23:29:16,003][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:29:16,008][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:30:20,927][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:20,929][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:20,990][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:20,991][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,036][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,037][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,041][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:30:21,044][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,045][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,045][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:30:21,120][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,120][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,177][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,178][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,235][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,236][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,264][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,265][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,329][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,330][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,330][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,330][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,348][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,348][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,365][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,365][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,387][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,387][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,402][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,403][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,430][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,431][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:21,431][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:30:21,431][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>16}
[2017-08-29T23:30:26,050][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:30:26,054][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:31:36,936][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:36,936][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:36,997][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:36,997][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,043][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,043][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,056][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,057][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,128][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,129][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,188][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,188][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,241][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,242][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,273][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,275][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,338][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,339][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,339][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,340][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,358][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,359][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,376][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,376][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,397][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,398][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,410][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,411][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,437][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,438][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:37,441][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:31:37,442][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>32}
[2017-08-29T23:31:41,093][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:31:41,097][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:33:08,942][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:08,942][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,003][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,004][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,054][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,055][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,062][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,062][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,136][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,137][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,198][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,199][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,249][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,250][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,279][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,280][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,346][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,346][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,347][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,347][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,368][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,369][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,383][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,384][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,403][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,404][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,459][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,473][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,473][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,474][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:09,474][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:33:09,477][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>64}
[2017-08-29T23:33:11,153][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:33:11,157][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:33:43,415][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:33:43,433][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:33:43,906][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:33:48,418][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T23:33:48,479][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2017-08-29T23:33:48,480][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T23:33:53,485][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2017-08-29T23:33:58,467][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2017-08-29T23:34:03,529][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2017-08-29T23:34:04,690][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:05,547][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:05,845][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:06,198][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:06,454][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:06,517][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:08,456][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2017-08-29T23:34:10,190][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:13,461][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:95:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:95:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/stud-0.0.23/lib/stud/interval.rb:95:in `sleep'"}]}}
[2017-08-29T23:34:15,682][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:16,351][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:18,478][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}]}}
[2017-08-29T23:34:57,258][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:57,544][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:57,988][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:58,012][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:58,046][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:58,254][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:58,481][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:58,803][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:59,041][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:59,251][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:34:59,483][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:01,042][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}]}}
[2017-08-29T23:35:02,424][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:02,608][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:06,041][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>1161, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/manticore-0.6.1-java/lib/manticore/response.rb:50:in `call'"}]}}
[2017-08-29T23:35:07,827][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:08,026][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:08,201][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:08,384][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:08,562][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:08,747][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:35:50,230][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:35:50,234][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:35:50,314][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:35:50,315][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:35:50,364][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:35:50,369][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:35:50,373][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:35:50,758][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:35:50,822][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:35:50,878][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:36:51,736][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,607][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,610][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,615][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,618][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,630][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,632][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,634][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,635][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,639][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,640][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,641][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,642][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,646][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,646][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,651][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,652][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,655][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,657][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,668][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:40:49,655][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,655][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,655][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,658][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:40:49,654][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2017-08-29T23:41:51,653][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,292][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,297][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,297][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,298][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,298][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,312][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,312][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,320][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,322][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,324][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,326][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,326][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,328][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,329][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,329][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,330][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,331][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,334][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,334][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,334][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-08-29T23:43:04,336][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,336][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,336][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,337][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketTimeout] Read timed out", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>4}
[2017-08-29T23:43:04,345][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:45:43,370][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:45:43,374][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:45:43,452][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:45:43,453][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:45:43,515][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:45:43,524][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:45:43,526][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:45:43,923][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:45:43,983][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:45:44,056][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:47:34,570][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:47:34,581][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:47:39,573][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2017-08-29T23:47:39,683][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>47, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/1.9/gems/logstash-input-beats-3.1.23-java/lib/logstash/inputs/beats.rb:206:in `run'"}], ["LogStash::Filters::Mutate", {"convert"=>{"accident"=>"integer", "death"=>"integer", "very_hurt"=>"integer", "light_hurt"=>"integer", "injury"=>"integer", "many"=>"integer", "severity"=>"integer", "total"=>"integer", "latitude"=>"float", "longitude"=>"float"}, "remove_field"=>["source", "type", "host", "message", "@version", "hostname", "name", "version", "tags", "input_type"], "rename"=>{"longitude"=>"[location][lon]", "latitude"=>"[location][lat]"}, "id"=>"49d85a939c1305abc70656cb07cfef25a6d2c4b0-3"}]=>[{"thread_id"=>30, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>31, "name"=>"[main]>worker1", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>32, "name"=>"[main]>worker2", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>33, "name"=>"[main]>worker3", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>34, "name"=>"[main]>worker4", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>35, "name"=>"[main]>worker5", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>36, "name"=>"[main]>worker6", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>37, "name"=>"[main]>worker7", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>38, "name"=>"[main]>worker8", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>39, "name"=>"[main]>worker9", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>40, "name"=>"[main]>worker10", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>41, "name"=>"[main]>worker11", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:121:in `lock'"}, {"thread_id"=>42, "name"=>"[main]>worker12", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>43, "name"=>"[main]>worker13", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>44, "name"=>"[main]>worker14", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}, {"thread_id"=>45, "name"=>"[main]>worker15", "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:147:in `lock'"}]}}
[2017-08-29T23:47:39,689][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2017-08-29T23:48:00,087][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:48:00,090][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:48:00,166][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:48:00,168][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:48:00,208][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:48:00,213][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:48:00,219][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>16, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>2000}
[2017-08-29T23:48:00,587][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2017-08-29T23:48:00,668][INFO ][logstash.pipeline        ] Pipeline main started
[2017-08-29T23:48:00,728][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:55:16,331][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-08-29T23:55:16,345][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:55:16,646][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-08-29T23:57:13,886][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:57:13,890][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:57:13,983][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:57:13,984][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:57:14,033][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:57:14,039][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:57:14,044][ERROR][logstash.pipeline        ] Error registering plugin {:plugin=>"#<LogStash::FilterDelegator:0x7b41dbab @id=\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", @klass=LogStash::Filters::Mutate, @metric_events=#<LogStash::Instrument::NamespacedMetric:0x4465f2b1 @metric=#<LogStash::Instrument::Metric:0x7b07d6dd @collector=#<LogStash::Instrument::Collector:0x69a8f3c7 @agent=nil, @metric_store=#<LogStash::Instrument::MetricStore:0x1cc1e1da @store=#<Concurrent::Map:0x00000000062668 entries=2 default_proc=nil>, @structured_lookup_mutex=#<Mutex:0x77da7889>, @fast_lookup=#<Concurrent::Map:0x0000000006266c entries=52 default_proc=nil>>>>, @namespace_name=[:stats, :pipelines, :main, :plugins, :filters, :\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", :events]>, @logger=#<LogStash::Logging::Logger:0x1c3602d8 @logger=#<Java::OrgApacheLoggingLog4jCore::Logger:0x159990bd>>, @filter=<LogStash::Filters::Mutate convert=>{\"accident\"=>\"integer\", \"death\"=>\"integer\", \"very_hurt\"=>\"integer\", \"light_hurt\"=>\"integer\", \"injury\"=>\"integer\", \"many\"=>\"integer\", \"severity\"=>\"integer\", \"total\"=>\"integer\", \"latitude\"=>\"double\", \"longitude\"=>\"double\"}, remove_field=>[\"source\", \"type\", \"host\", \"message\", \"@version\", \"hostname\", \"name\", \"version\", \"tags\", \"input_type\"], rename=>{\"longitude\"=>\"[location][lon]\", \"latitude\"=>\"[location][lat]\"}, id=>\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", enable_metric=>true, periodic_flush=>false>>", :error=>"translation missing: en.logstash.agent.configuration.invalid_plugin_register"}
[2017-08-29T23:57:14,050][ERROR][logstash.agent           ] Pipeline aborted due to error {:exception=>#<LogStash::ConfigurationError: translation missing: en.logstash.agent.configuration.invalid_plugin_register>, :backtrace=>["X:/elastic_stack/logstash-5.5.2/vendor/bundle/jruby/1.9/gems/logstash-filter-mutate-3.1.5/lib/logstash/filters/mutate.rb:189:in `register'", "org/jruby/RubyHash.java:1342:in `each'", "X:/elastic_stack/logstash-5.5.2/vendor/bundle/jruby/1.9/gems/logstash-filter-mutate-3.1.5/lib/logstash/filters/mutate.rb:183:in `register'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:281:in `register_plugin'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:292:in `register_plugins'", "org/jruby/RubyArray.java:1613:in `each'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:292:in `register_plugins'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:302:in `start_workers'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:226:in `run'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/agent.rb:398:in `start_pipeline'"]}
[2017-08-29T23:57:14,092][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:57:17,064][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-08-29T23:58:25,042][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2017-08-29T23:58:25,046][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2017-08-29T23:58:25,128][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2017-08-29T23:58:25,130][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-08-29T23:58:25,172][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-08-29T23:58:25,180][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1"]}
[2017-08-29T23:58:25,186][ERROR][logstash.pipeline        ] Error registering plugin {:plugin=>"#<LogStash::FilterDelegator:0x9b9224b @id=\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", @klass=LogStash::Filters::Mutate, @metric_events=#<LogStash::Instrument::NamespacedMetric:0x173fe4bf @metric=#<LogStash::Instrument::Metric:0x4ec0d20e @collector=#<LogStash::Instrument::Collector:0x8029570 @agent=nil, @metric_store=#<LogStash::Instrument::MetricStore:0x48e95541 @store=#<Concurrent::Map:0x00000000062668 entries=2 default_proc=nil>, @structured_lookup_mutex=#<Mutex:0x209b4aff>, @fast_lookup=#<Concurrent::Map:0x0000000006266c entries=52 default_proc=nil>>>>, @namespace_name=[:stats, :pipelines, :main, :plugins, :filters, :\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", :events]>, @logger=#<LogStash::Logging::Logger:0x74b60d35 @logger=#<Java::OrgApacheLoggingLog4jCore::Logger:0x4a2f18db>>, @filter=<LogStash::Filters::Mutate convert=>{\"accident\"=>\"integer\", \"death\"=>\"integer\", \"very_hurt\"=>\"integer\", \"light_hurt\"=>\"integer\", \"injury\"=>\"integer\", \"many\"=>\"integer\", \"severity\"=>\"integer\", \"total\"=>\"integer\", \"latitude\"=>\"double\", \"longitude\"=>\"double\"}, remove_field=>[\"source\", \"type\", \"host\", \"message\", \"@version\", \"hostname\", \"name\", \"version\", \"tags\", \"input_type\"], rename=>{\"longitude\"=>\"[location][lon]\", \"latitude\"=>\"[location][lat]\"}, id=>\"87c85ade7ca21e0448c1dcf2c4438e6bbc482bc1-3\", enable_metric=>true, periodic_flush=>false>>", :error=>"translation missing: en.logstash.agent.configuration.invalid_plugin_register"}
[2017-08-29T23:58:25,194][ERROR][logstash.agent           ] Pipeline aborted due to error {:exception=>#<LogStash::ConfigurationError: translation missing: en.logstash.agent.configuration.invalid_plugin_register>, :backtrace=>["X:/elastic_stack/logstash-5.5.2/vendor/bundle/jruby/1.9/gems/logstash-filter-mutate-3.1.5/lib/logstash/filters/mutate.rb:189:in `register'", "org/jruby/RubyHash.java:1342:in `each'", "X:/elastic_stack/logstash-5.5.2/vendor/bundle/jruby/1.9/gems/logstash-filter-mutate-3.1.5/lib/logstash/filters/mutate.rb:183:in `register'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:281:in `register_plugin'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:292:in `register_plugins'", "org/jruby/RubyArray.java:1613:in `each'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:292:in `register_plugins'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:302:in `start_workers'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/pipeline.rb:226:in `run'", "X:/elastic_stack/logstash-5.5.2/logstash-core/lib/logstash/agent.rb:398:in `start_pipeline'"]}
[2017-08-29T23:58:25,242][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-08-29T23:58:28,212][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
